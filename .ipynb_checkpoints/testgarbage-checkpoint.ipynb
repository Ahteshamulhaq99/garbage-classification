{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18729eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cafc45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import torch.nn.functional as F \n",
    "import torch \n",
    "import numpy as np \n",
    "\n",
    "def show_image(image,label,get_denormalize = True):\n",
    "    \n",
    "    image = image.permute(1,2,0)\n",
    "    mean = torch.FloatTensor([0.485, 0.456, 0.406])\n",
    "    std = torch.FloatTensor([0.229, 0.224, 0.225])\n",
    "    \n",
    "    if get_denormalize == True:\n",
    "        image = image*std + mean\n",
    "        image = np.clip(image,0,1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(label)\n",
    "        \n",
    "    else: \n",
    "        plt.imshow(image)\n",
    "        plt.title(label)\n",
    "\n",
    "def show_grid(image,title = None):\n",
    "    \n",
    "    image = image.permute(1,2,0)\n",
    "    mean = torch.FloatTensor([0.485, 0.456, 0.406])\n",
    "    std = torch.FloatTensor([0.229, 0.224, 0.225])\n",
    "    \n",
    "    image = image*std + mean\n",
    "    image = np.clip(image,0,1)\n",
    "    \n",
    "    plt.figure(figsize=[15, 15])\n",
    "    plt.imshow(image)\n",
    "    if title != None:\n",
    "        plt.title(title)\n",
    "\n",
    "\n",
    "def accuracy(y_pred,y_true):\n",
    "    y_pred = F.softmax(y_pred,dim = 1)\n",
    "    top_p,top_class = y_pred.topk(1,dim = 1)\n",
    "    equals = top_class == y_true.view(*top_class.shape)\n",
    "    return torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "\n",
    "def view_classify(image,ps,label):\n",
    "    \n",
    "    class_name = ['clean', 'garbage']\n",
    "    classes = np.array(class_name)\n",
    "\n",
    "    ps = ps.cpu().data.numpy().squeeze()\n",
    "    \n",
    "    image = image.permute(1,2,0)\n",
    "    mean = torch.FloatTensor([0.485, 0.456, 0.406])\n",
    "    std = torch.FloatTensor([0.229, 0.224, 0.225])\n",
    "    \n",
    "    \n",
    "    image = image*std + mean\n",
    "    img = np.clip(image,0,1)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(8,12), ncols=2)\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Ground Truth : {}'.format(class_name[label]))\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(classes, ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(classes)\n",
    "    ax2.set_yticklabels(classes)\n",
    "    ax2.set_title('Predicted Class')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "409d828a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'dls'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6cc502df8069>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'exm1.mp4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload_learner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'garbageModel.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# Read until video is completed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36mload_learner\u001b[1;34m(fname, cpu, pickle_module)\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cpu'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcpu\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'to_fp32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_fp32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'dls'"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "\n",
    "  epochs =20                              # No. of epochs for training the model\n",
    "  lr = 0.001                              # Learning rate\n",
    "  batch_size = 16                         # Batch Size for Dataset\n",
    "\n",
    "  model_name = 'tf_efficientnet_b4_ns'    # Model name (we are going to import model from timm)\n",
    "  img_size = 224                          # Resize all the images to be 224 by 224\n",
    "\n",
    "  # going to be used for loading dataset\n",
    "  train_path='data/train'\n",
    "  validate_path='data/val'\n",
    "  test_path='data/test'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"On which device we are on:{}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d8732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as T,datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177caad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = T.Compose([\n",
    "                             \n",
    "         T.Resize(size=(CFG.img_size,CFG.img_size)), # Resizing the image to be 224 by 224\n",
    "         T.RandomRotation(degrees=(-20,+20)), #Randomly Rotate Images by +/- 20 degrees, Image argumentation for each epoch\n",
    "         T.ToTensor(), #converting the dimension from (height,weight,channel) to (channel,height,weight) convention of PyTorch\n",
    "         T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) # Normalize by 3 means 3 StD's of the image net, 3 channels\n",
    "\n",
    "])\n",
    "\n",
    "validate_transform = T.Compose([\n",
    "                             \n",
    "     T.Resize(size=(CFG.img_size,CFG.img_size)), # Resizing the image to be 224 by 224\n",
    "     #T.RandomRotation(degrees=(-20,+20)), #NO need for validation\n",
    "     T.ToTensor(), #converting the dimension from (height,weight,channel) to (channel,height,weight) convention of PyTorch\n",
    "     T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) # Normalize by 3 means 3 StD's of the image net, 3 channels\n",
    "\n",
    "])\n",
    "\n",
    "test_transform = T.Compose([\n",
    "                             \n",
    "         T.Resize(size=(CFG.img_size,CFG.img_size)), # Resizing the image to be 224 by 224\n",
    "         #T.RandomRotation(degrees=(-20,+20)), #NO need for validation\n",
    "         T.ToTensor(), #converting the dimension from (height,weight,channel) to (channel,height,weight) convention of PyTorch\n",
    "         T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) # Normalize by 3 means 3 StD's of the image net, 3 channels\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b480b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset=datasets.ImageFolder(CFG.train_path,transform=train_transform)\n",
    "print(\"Trainset Size:  {}\".format(len(trainset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "validateset=datasets.ImageFolder(CFG.validate_path,transform=validate_transform)\n",
    "print(\"validateset Size:  {}\".format(len(validateset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61448b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img,label = trainset[20]\n",
    "#print(trainset.class_to_idx)\n",
    "\n",
    "class_name =[\"clean\",\"garbage\"]\n",
    "show_image(img,class_name[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df1c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img,label = trainset[20]\n",
    "#print(trainset.class_to_idx)\n",
    "\n",
    "class_name =[\"clean\",\"garbage\"]\n",
    "show_image(img,class_name[label]) \n",
    "\n",
    "# randomly rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc745d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7005df3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
